{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Brief Tutorial on Text Processing Using NLTK and Scikit-Learn\n",
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\CPEEB25\\\\CSE7306c\\\\20170325_Batch25_Day2_TextMining'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\CPEEB25\\\\CSE7306c\\\\20170325_Batch25_Day2_TextMining\\\\data'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"E:\\\\CPEEB25\\\\CSE7306c\\\\20170325_Batch25_Day2_TextMining\\\\data\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shakespeare-macbeth.txt', 'sms.tsv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('of', 9), ('and', 8), ('in', 5), ('she', 4), ('the', 4), ('lee', 3), ('to', 2), ('new', 2), ('congregations', 2), ('jersey', 2), ('church', 2), ('an', 2), ('methodists', 2), ('founder', 1), ('domestic', 1), ('four', 1), ('meditation', 1), ('children', 1), ('had', 1), ('vigor', 1), ('africanamerican', 1), ('they', 1), ('feelings', 1), ('profound', 1), ('married', 1), ('joined', 1), ('spiritual', 1), ('infancy', 1), ('energy', 1), ('experienced', 1), ('depression', 1), ('richard', 1), ('worshiped', 1), ('demons', 1), ('reverend', 1), ('various', 1), ('hill', 1), ('who', 1), ('eternal', 1), ('emotional', 1), ('by', 1), ('extreme', 1), ('on', 1), ('baptism', 1), ('inspired', 1), ('months', 1), ('prior', 1), ('roman', 1), ('mixed', 1), ('among', 1), ('hearing', 1), ('visions', 1), ('sermon', 1), ('pastored', 1), ('from', 1), ('her', 1), ('there', 1), ('protracted', 1), ('philadelphia', 1), ('whom', 1), ('joseph', 1), ('terrifying', 1), ('white', 1), ('was', 1), ('catholics', 1), ('methodist', 1), ('baptized', 1), ('anxiety', 1), ('ecstasy', 1), ('labored', 1), ('ennui', 1), ('stages', 1), ('prayer', 1), ('moved', 1), ('episcopal', 1), ('as', 1), ('periods', 1), ('allen', 1), ('physical', 1), ('conversion', 1), ('jarena', 1), ('six', 1), ('snow', 1), ('perdition', 1), ('several', 1), ('bethel', 1), ('fever', 1), ('after', 1), ('a', 1), ('died', 1), ('1811', 1), ('1807', 1), ('fasting', 1), ('1804', 1), ('african', 1)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def get_tokens():\n",
    "    with open('anb-jarena-lee.txt', 'r') as shakes:\n",
    "        text = shakes.read()\n",
    "        lowers = text.lower()\n",
    "        #remove the punctuation using the character deletion step of translate\n",
    "        no_punctuation = lowers.translate(None, string.punctuation)\n",
    "        tokens = nltk.word_tokenize(no_punctuation)\n",
    "        return tokens\n",
    "\n",
    "tokens = get_tokens()\n",
    "count = Counter(tokens)\n",
    "print count.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Word Removal\n",
    "These are uninformative, so let's remove the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lee', 3), ('church', 2), ('methodists', 2), ('new', 2), ('congregations', 2), ('jersey', 2), ('among', 1), ('spiritual', 1), ('married', 1), ('founder', 1), ('infancy', 1), ('roman', 1), ('energy', 1), ('prayer', 1), ('domestic', 1), ('hearing', 1), ('four', 1), ('episcopal', 1), ('fever', 1), ('periods', 1), ('allen', 1), ('meditation', 1), ('visions', 1), ('children', 1), ('sermon', 1), ('physical', 1), ('pastored', 1), ('conversion', 1), ('six', 1), ('jarena', 1), ('richard', 1), ('stages', 1), ('worshiped', 1), ('philadelphia', 1), ('demons', 1), ('ecstasy', 1), ('reverend', 1), ('joseph', 1), ('various', 1), ('terrifying', 1), ('perdition', 1), ('white', 1), ('several', 1), ('hill', 1), ('vigor', 1), ('catholics', 1), ('bethel', 1), ('experienced', 1), ('protracted', 1), ('moved', 1), ('eternal', 1), ('depression', 1), ('africanamerican', 1), ('1804', 1), ('1811', 1), ('baptized', 1), ('feelings', 1), ('ennui', 1), ('died', 1), ('extreme', 1), ('1807', 1), ('fasting', 1), ('anxiety', 1), ('profound', 1), ('snow', 1), ('inspired', 1), ('months', 1), ('joined', 1), ('prior', 1), ('labored', 1), ('african', 1), ('mixed', 1), ('emotional', 1), ('methodist', 1), ('baptism', 1)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokens = get_tokens()\n",
    "stop = stopwords.words(\"english\")\n",
    "token_withOutStop = [token for token in tokens if token not in stop]\n",
    "count = Counter(token_withOutStop)\n",
    "print count.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'methodist', 3), (u'lee', 3), (u'church', 2), (u'new', 2), (u'congreg', 2), (u'jersey', 2), (u'among', 1), (u'founder', 1), (u'ecstasi', 1), (u'feel', 1), (u'1811', 1), (u'move', 1), (u'period', 1), (u'terrifi', 1), (u'month', 1), (u'protract', 1), (u'children', 1), (u'fever', 1), (u'baptiz', 1), (u'infanc', 1)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "tokens_stemmed = [stemmer.stem(token) for token in token_withOutStop]\n",
    "count = Counter(tokens_stemmed)\n",
    "print count.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-Idf in Scikit-Learn\n",
    "Unfortunately, calculating tf-idf is not available in NLTK so we'll use another data analysis library, scikit-learn. Scikit-learn has a built in Tf-Idf implementation and we can use NLTK's tokenizer and stemmer to preprocess the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 1804 after several months of profound spiritual anxiety jarena lee\n",
      "moved from new jersey to philadelphia there she labored as a domestic\n",
      "and worshiped among white congregations of roman catholics and mixed\n",
      "congregations of methodists on hearing an inspired sermon by the\n",
      "reverend richard allen founder of the bethel african methodist\n",
      "episcopal church lee joined the methodists she was baptized in 1807\n",
      "prior to her baptism she experienced the various physical and emotional\n",
      "stages of conversion terrifying visions of demons and eternal\n",
      "perdition extreme feelings of ecstasy and depression protracted\n",
      "periods of meditation fasting and prayer ennui and fever energy and\n",
      "vigor in 1811 she married joseph lee who pastored an africanamerican\n",
      "church in snow hill new jersey they had six children four of whom\n",
      "died in infancy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## a) Read 'anb-jarena-lee.txt' file.\n",
    "## b) Convert all characters to lower case.\n",
    "## c) remove all punctuations from the text.\n",
    "token_dict = {}\n",
    "shakes = open('anb-jarena-lee.txt', 'r')\n",
    "text = shakes.read()\n",
    "lowers = text.lower()\n",
    "no_punctuation = lowers.translate(None, string.punctuation)\n",
    "\n",
    "print(no_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<type 'file'>: 'in 1804 after several months of profound spiritual anxiety jarena lee\\nmoved from new jersey to philadelphia there she labored as a domestic\\nand worshiped among white congregations of roman catholics and mixed\\ncongregations of methodists on hearing an inspired sermon by the\\nreverend richard allen founder of the bethel african methodist\\nepiscopal church lee joined the methodists she was baptized in 1807\\nprior to her baptism she experienced the various physical and emotional\\nstages of conversion terrifying visions of demons and eternal\\nperdition extreme feelings of ecstasy and depression protracted\\nperiods of meditation fasting and prayer ennui and fever energy and\\nvigor in 1811 she married joseph lee who pastored an africanamerican\\nchurch in snow hill new jersey they had six children four of whom\\ndied in infancy\\n'}\n",
      "['in 1804 after several months of profound spiritual anxiety jarena lee\\nmoved from new jersey to philadelphia there she labored as a domestic\\nand worshiped among white congregations of roman catholics and mixed\\ncongregations of methodists on hearing an inspired sermon by the\\nreverend richard allen founder of the bethel african methodist\\nepiscopal church lee joined the methodists she was baptized in 1807\\nprior to her baptism she experienced the various physical and emotional\\nstages of conversion terrifying visions of demons and eternal\\nperdition extreme feelings of ecstasy and depression protracted\\nperiods of meditation fasting and prayer ennui and fever energy and\\nvigor in 1811 she married joseph lee who pastored an africanamerican\\nchurch in snow hill new jersey they had six children four of whom\\ndied in infancy\\n']\n"
     ]
    }
   ],
   "source": [
    "#Store the pre-processed text to Token_dictionary variable as type files\n",
    "token_dict[file] = no_punctuation\n",
    "\n",
    "print token_dict\n",
    "print(token_dict.values())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1807',\n",
       " u'1811',\n",
       " u'african',\n",
       " u'africanamerican',\n",
       " u'after',\n",
       " u'allen',\n",
       " u'among',\n",
       " u'an',\n",
       " u'and']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tf = CountVectorizer()\n",
    "\n",
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "tf.fit(token_dict.values())\n",
    "\n",
    "# examine the fitted vocabulary\n",
    "features = tf.get_feature_names()\n",
    "features[1:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1804</th>\n",
       "      <th>1807</th>\n",
       "      <th>1811</th>\n",
       "      <th>african</th>\n",
       "      <th>africanamerican</th>\n",
       "      <th>after</th>\n",
       "      <th>allen</th>\n",
       "      <th>among</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>...</th>\n",
       "      <th>they</th>\n",
       "      <th>to</th>\n",
       "      <th>various</th>\n",
       "      <th>vigor</th>\n",
       "      <th>visions</th>\n",
       "      <th>was</th>\n",
       "      <th>white</th>\n",
       "      <th>who</th>\n",
       "      <th>whom</th>\n",
       "      <th>worshiped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1804  1807  1811  african  africanamerican  after  allen  among  an  and  \\\n",
       "0     1     1     1        1                1      1      1      1   2    8   \n",
       "\n",
       "     ...      they  to  various  vigor  visions  was  white  who  whom  \\\n",
       "0    ...         1   2        1      1        1    1      1    1     1   \n",
       "\n",
       "   worshiped  \n",
       "0          1  \n",
       "\n",
       "[1 rows x 94 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "tf_dtm = tf.transform(token_dict.values())\n",
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(tf_dtm.toarray(), columns=tf.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a text-based dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anb-jarena-lee.txt', 'shakespeare-macbeth.txt', 'sms.tsv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"E:\\\\CPEEB25\\\\CSE7306c\\\\20170325_Batch25_Day2_TextMining\\\\data\")\n",
    "os.getcwd()\n",
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'sms.tsv'\n",
    "sms = pd.read_table(path, header=None, names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the shape\n",
    "sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 10 rows\n",
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "sms.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "sms['label_num'] = sms.label.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0\n",
       "1   ham                      Ok lar... Joking wif u oni...          0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
       "3   ham  U dun say so early hor... U c already then say...          0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...          1\n",
       "6   ham  Even my brother is not like to speak with me. ...          0\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...          0\n",
       "8  spam  WINNER!! As a valued network customer you have...          1\n",
       "9  spam  Had your mobile 11 months or more? U R entitle...          1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the conversion worked\n",
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572L,)\n",
      "(5572L,)\n"
     ]
    }
   ],
   "source": [
    "# how to define X and y (from the SMS data) for use with COUNTVECTORIZER\n",
    "X = sms.message\n",
    "y = sms.label_num\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4179L,)\n",
      "(1393L,)\n",
      "(4179L,)\n",
      "(1393L,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X_train)\n",
    "X_train_dtm_a = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# equivalently: combine fit and transform into a single step\n",
    "X_train_dtm_b = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print X_train_dtm_a\n",
    "#print X_train_dtm_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1393x7456 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 17604 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and evaluating a model\n",
    "\n",
    "We will use multinomial Naive Bayes:\n",
    "\n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_a = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm_a\n",
    "nb_a.fit(X_train_dtm_a, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm_a\n",
    "y_pred_class_a = nb_a.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98851399856424982"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1203,    5],\n",
       "       [  11,  174]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_b = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm_a\n",
    "nb_b.fit(X_train_dtm_b, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class_b = nb_a.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98851399856424982"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1203,    5],\n",
       "       [  11,  174]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class_a)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
